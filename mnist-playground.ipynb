{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-15T16:22:47.365023Z","iopub.status.busy":"2024-07-15T16:22:47.364626Z","iopub.status.idle":"2024-07-15T16:22:49.349077Z","shell.execute_reply":"2024-07-15T16:22:49.347576Z","shell.execute_reply.started":"2024-07-15T16:22:47.364975Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of training data: (60000, 785)\n","Shape of test_data: (10000, 785)\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import numpy.typing as npt\n","# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import skimage as ski\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","        \n","\n","datapath_train = \"./mnist_data/mnist_train.csv\"\n","datapath_test = \"./mnist_data/mnist_test.csv\"\n","\n","datatype = np.float64\n","\n","train_data = np.loadtxt(datapath_train, dtype=datatype, delimiter=\",\", skiprows=1)\n","test_data = np.loadtxt(datapath_test, dtype=datatype, delimiter=\",\", skiprows=1)\n","print(f\"Shape of training data: {train_data.shape}\")\n","print(f\"Shape of test_data: {test_data.shape}\")\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of train labels: (60000,)\n","Shape of train values: (60000, 784)\n","Shape of test labels: (10000,)\n","Shape of test values: (10000, 784)\n"]}],"source":["train_labels: npt.NDArray = train_data[:, 0].astype(np.uint8)\n","print(f\"Shape of train labels: {train_labels.shape}\")\n","train_vals = (train_data[:, 1:] - 128) / 128\n","print(f\"Shape of train values: {train_vals.shape}\")\n","\n","\n","test_labels: npt.NDArray = test_data[:, 0].astype(np.uint8)\n","print(f\"Shape of test labels: {test_labels.shape}\")\n","test_vals = (test_data[:, 1:] - 128) / 128\n","print(f\"Shape of test values: {test_vals.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sigmoid(x: npt.NDArray) -> npt.NDArray:\n","    return 1 / (1 + np.exp(-x))\n","\n","def tanh(x: npt.NDArray) -> npt.NDArray:\n","    return np.tanh(x)\n","\n","def ReLU(x: npt.NDArray) -> npt.NDArray:\n","    \"\"\"ReLU(x) = max(0, x)\"\"\"\n","    return x * (x > 0)\n","\n","def percentages(x: npt.NDArray) -> npt.NDArray:\n","    return np.exp(x) / np.sum(np.exp(x))\n","\n","def random_weights(dimensions: npt.ArrayLike, low: float = -1, high: float = 1) -> npt.NDArray:\n","    range = high - low\n","    return np.random.rand(*dimensions) * range + low\n","\n","def print_percentages(percentages_array: npt.NDArray) -> None:\n","    for i, p in enumerate(percentages_array):\n","        print(f\"{i} = {round(p * 100, 3)}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sigmoid_derivative(x: npt.NDArray):\n","    return sigmoid(x) * (1 - sigmoid(x))\n","\n","def ReLU_derivative(x: npt.NDArray):\n","    return 1 * (x > 0)\n","\n","def tanh_derivative(x: npt.NDArray):\n","    t = np.tanh(x)\n","    return 1 - (t * t)\n","\n","def softmax(x: npt.NDArray):\n","    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n","    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n","    \n","def cross_entropy_loss(predictions, labels):\n","    num_samples = predictions.shape[0]\n","    correct_logprobs = -np.log(predictions[range(num_samples), labels.astype(int)])\n","    loss = np.sum(correct_logprobs) / num_samples\n","\n","    return loss\n","\n","    # hidden_weight_gradient = \n","    # dCdW = layer_activation * dCdz\n","    # dCdb = dCdz\n","    # dCda = layer_weights * dCdz\n","\n","    # return np.array(dCdW + dCdb + dCda)\n","\n","# gain = 0.1\n","# learning_rate = 0.5\n","# output_gradient = tanh_derivative(output_loss)\n","#hidden_gradient = ReLU_derivative(np.dot(output_loss, hidden_layer_weights))\n","\n","#calculate_loss_gradient(output_layer_weights, activations, loss, dist)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m     batch_targets \u001b[38;5;241m=\u001b[39m train_labels[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_vector, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_inputs, batch_targets):\n\u001b[1;32m---> 51\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mbackpropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_vals)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[1;32mIn[5], line 28\u001b[0m, in \u001b[0;36mbackpropagation\u001b[1;34m(input_vector, target, learning_rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m output_error \u001b[38;5;241m=\u001b[39m (output_layer_a \u001b[38;5;241m-\u001b[39m y_true)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Compute the hidden layer error\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m hidden_error \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mdot(output_error, output_layer_weights) \u001b[38;5;241m*\u001b[39m ReLU_derivative(hidden_layer_z)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Update weights and biases\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Output layer\u001b[39;00m\n\u001b[0;32m     32\u001b[0m output_layer_weights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(output_error, hidden_layer_a)\n","File \u001b[1;32mw:\\DevDev\\Machine Learning\\venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[1;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[1;32mw:\\DevDev\\Machine Learning\\venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mw:\\DevDev\\Machine Learning\\venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n","File \u001b[1;32mw:\\DevDev\\Machine Learning\\venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_mid_layer = 1000\n","\n","# 784 -> `hidden_layer_size` -> 10\n","\n","hidden_layer_weights = np.random.normal(0, 0.1, (hidden_layer_size, 784)) #random_weights((hidden_layer_size, 784)) # Random values in the range [-1, 1)\n","hidden_layer_bias = np.zeros((hidden_layer_size,), dtype=datatype)\n","\n","output_layer_weights = np.random.normal(0, 0.1, (10, hidden_layer_size)) # random_weights((10, hidden_layer_size))\n","output_layer_bias = np.zeros((10,), dtype=datatype)\n","truth_table = (np.identity(10, dtype=datatype))  # 0 to 1\n","\n","def backpropagation(input_vector, target, learning_rate=0.01):\n","    global hidden_layer_weights, output_layer_weights\n","    global hidden_layer_bias, output_layer_bias\n","\n","    # Feedforward\n","    hidden_layer_z = np.dot(hidden_layer_weights, input_vector).T + hidden_layer_bias\n","    hidden_layer_a = ReLU(hidden_layer_z)\n","    output_layer_z = np.dot(output_layer_weights, hidden_layer_a.T).T + output_layer_bias\n","    output_layer_a = softmax(output_layer_z)\n","\n","    # Compute the output layer error\n","    y_true = truth_table[int(target)]\n","    output_error = (output_layer_a - y_true)\n","\n","    # Compute the hidden layer error\n","    hidden_error = np.dot(output_error, output_layer_weights) * ReLU_derivative(hidden_layer_z)\n","\n","    # Update weights and biases\n","    # Output layer\n","    output_layer_weights -= learning_rate * np.outer(output_error, hidden_layer_a)\n","    output_layer_bias -= learning_rate * output_error\n","\n","    # Hidden layer\n","    hidden_layer_weights -= learning_rate * np.outer(hidden_error.T, input_vector)\n","    hidden_layer_bias -= learning_rate * hidden_error.flatten()\n","\n","    return np.sum((output_layer_a - y_true) ** 2)  # Return the loss\n","    \n","\n","# Training loop\n","epochs = 10\n","batch_size = 32\n","for epoch in range(epochs):\n","    total_loss = 0\n","    for i in range(0, len(train_vals), batch_size):\n","        batch_inputs = train_vals[i:i+batch_size]\n","        batch_targets = train_labels[i:i+batch_size]\n","        for input_vector, target in zip(batch_inputs, batch_targets):\n","            loss = backpropagation(input_vector, target)\n","            total_loss += loss\n","    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_vals)}\")\n"]},{"cell_type":"code","execution_count":220,"metadata":{},"outputs":[],"source":["validation_set_size = 1000\n","training_set_vals = train_vals[validation_set_size:]\n","training_set_labels = train_labels[validation_set_size:]\n","\n","validation_set_vals = train_vals[0:validation_set_size]\n","validation_set_labels = train_labels[0:validation_set_size]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test the model\n","def test():\n","    correct = 0\n","    for input_vector, target in zip(validation_set_vals, validation_set_labels):\n","        hidden_layer_a = ReLU(np.dot(hidden_layer_weights, input_vector).T + hidden_layer_bias)\n","        output_layer_a = softmax(np.dot(output_layer_weights, hidden_layer_a.T).T + output_layer_bias)\n","        prediction = np.argmax(output_layer_a)\n","        if prediction == target:\n","            correct += 1\n","            \n","    accuracy = correct / validation_set_size\n","    #print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n","    return accuracy"]},{"cell_type":"code","execution_count":229,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0: total loss = 13902.09510813158\n","Accuracy on test: 0.893\n","Epoch: 1: total loss = 8171.221635887625\n","Accuracy on test: 0.911\n","Epoch: 2: total loss = 6861.323635022885\n","Accuracy on test: 0.925\n","Epoch: 3: total loss = 5969.2241276696495\n","Accuracy on test: 0.933\n","Epoch: 4: total loss = 5324.019550548197\n","Accuracy on test: 0.936\n","Epoch: 5: total loss = 4822.959044400571\n","Accuracy on test: 0.94\n","Epoch: 6: total loss = 4446.225607921637\n","Accuracy on test: 0.942\n","Epoch: 7: total loss = 4127.117522492192\n","Accuracy on test: 0.944\n","Epoch: 8: total loss = 3842.213894313576\n","Accuracy on test: 0.95\n","Epoch: 9: total loss = 3621.197622261547\n","Accuracy on test: 0.951\n","Epoch: 10: total loss = 3438.772418578457\n","Accuracy on test: 0.953\n","Epoch: 11: total loss = 3236.133259648965\n","Accuracy on test: 0.953\n","Did not improve: exiting.\n"]}],"source":["hidden_layer_size = 100\n","hidden_layer_weights = np.random.normal(0, 0.1, (hidden_layer_size, 784)) #random_weights((hidden_layer_size, 784)) # Random values in the range [-1, 1)\n","hidden_layer_bias = np.zeros((hidden_layer_size,), dtype=datatype)\n","\n","output_layer_weights = np.random.normal(0, 0.1, (10, hidden_layer_size)) # random_weights((10, hidden_layer_size))\n","output_layer_bias = np.zeros((10,), dtype=datatype)\n","truth_table = (np.identity(10, dtype=datatype))  # 0 to 1\n","\n","def feedforward(input_vector: npt.NDArray):\n","    # Feedforward\n","    hidden_layer_z = np.dot(input_vector, hidden_layer_weights.T) + hidden_layer_bias\n","    hidden_layer_a = ReLU(hidden_layer_z)\n","    output_layer_z = np.dot(hidden_layer_a, output_layer_weights.T) + output_layer_bias\n","    output_layer_a = softmax(output_layer_z)\n","\n","    return output_layer_a, hidden_layer_a\n","\n","def train(learning_rate=0.01):\n","    global hidden_layer_weights, output_layer_weights\n","    global hidden_layer_bias, output_layer_bias\n","\n","    epochs = 100\n","    batch_size = 32\n","    best_accuracy = 0\n","\n","    # In each epoch, shuffle the order of the training images so the model does not learn the order\n","    for epoch_num in range(epochs):\n","        shuffled_indices = np.arange(len(training_set_labels))\n","        np.random.shuffle(shuffled_indices)\n","        shuffled_vals = training_set_vals[shuffled_indices]\n","        shuffled_labels = training_set_labels[shuffled_indices]\n","        total_loss = 0\n","\n","        # Update the weights in batches to avoid training in any particular direction\n","        for batch_num in range(0, len(training_set_vals) // batch_size):\n","            batch_start = batch_num * batch_size\n","            batch_end = batch_start + batch_size\n","\n","            input_batch = shuffled_vals[batch_start : batch_end]\n","            label_batch = shuffled_labels[batch_start: batch_end]\n","\n","            # feedforward\n","            hidden_z = np.dot(input_batch, hidden_layer_weights.T) + hidden_layer_bias\n","            hidden_a = ReLU(hidden_z)\n","            output_z = np.dot(hidden_a, output_layer_weights.T) + output_layer_bias\n","            output_a = softmax(output_z)\n","\n","            # backprop\n","            y_true = np.eye(10)[label_batch]\n","            output_error = output_a - y_true\n","            hidden_error = np.dot(output_error, output_layer_weights) * ReLU_derivative(hidden_a)\n","            \n","            # Update output layer\n","            output_layer_weights -= learning_rate * (np.dot(output_error.T, hidden_a) / batch_size)\n","            output_layer_bias -= learning_rate * np.mean(output_error, axis=0)\n","\n","            # Update hidden layer\n","            hidden_layer_weights -= learning_rate * (np.dot(hidden_error.T, input_batch) / batch_size)\n","            hidden_layer_bias -= learning_rate * np.mean(hidden_error, axis=0)\n","\n","            total_loss += np.sum(output_error ** 2)\n","\n","        print(f\"Epoch: {epoch_num}: total loss = {total_loss}\")\n","\n","        accuracy = test()\n","        print(f\"Accuracy on test: {accuracy}\")\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","        else:\n","            print(\"Did not improve: exiting.\")\n","            break\n","\n","        learning_rate *= 0.99\n","\n","\n","\n","train()"]},{"cell_type":"code","execution_count":237,"metadata":{},"outputs":[],"source":["np.isin(validation_set_vals[0], training_set_vals)"]},{"cell_type":"code","execution_count":231,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0.0012000000000000001\n","1 0.0001\n","2 0.7207\n","3 0.0005\n","4 0.1297\n","5 0.0001\n","6 0.0358\n","7 0.003\n","8 0.0381\n","9 0.0702\n"]},{"data":{"text/plain":["np.int64(2)"]},"execution_count":231,"metadata":{},"output_type":"execute_result"}],"source":["from PIL import Image\n","\n","img = Image.open(\"MySevenDark.png\").convert('L')\n","\n","img_array = ((np.array(img, dtype=datatype) - 128) / 128)\n","img_flat = img_array.T.flatten()\n","\n","for idx, i in enumerate(feedforward(img_flat)[0]):\n","    print(idx, (i // 0.0001) * 0.0001) \n","feedforward(img_flat)[0].argmax()"]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[],"source":["import pygame\n","pygame.init()\n","screen = pygame.display.set_mode((280, 280))\n","done = False\n","\n","pygame.font.init()\n","f = pygame.font.SysFont(None, 12)\n","def draw_num_at_pos(surface, num: int, position):\n","    rendered_num = f.render(f\"{num}\", True, (255, 255, 255))\n","    rn_rect = rendered_num.get_rect()\n","    rn_rect.center = position\n","\n","    surface.blit(rendered_num, rn_rect)\n","\n","draw_surf = pygame.Surface((280, 280))\n","model_surf = pygame.Surface((28, 28))\n","clock = pygame.time.Clock()\n","while not done:\n","    for event in pygame.event.get():\n","        if event.type == pygame.QUIT:\n","            done = True\n","\n","        if event.type == pygame.KEYDOWN:\n","            if event.key == pygame.K_ESCAPE:\n","                done = True\n","\n","            if event.key == pygame.K_SPACE:\n","                draw_surf.fill((0, 0, 0))\n","\n","            if event.key == pygame.K_F2:\n","                model_surfarray = pygame.surfarray.pixels3d(model_surf).astype(datatype)\n","                model_surfarray = model_surfarray.T\n","                pygame.image.save(model_surf, \"model_img.png\")\n","\n","    mouse_buttons = pygame.mouse.get_pressed()\n","    if mouse_buttons[0]:\n","        pygame.draw.aacircle(draw_surf, (255, 255, 255), pygame.mouse.get_pos(), 8)\n","    elif mouse_buttons[2]:\n","        pygame.draw.aacircle(draw_surf, (0, 0, 0), pygame.mouse.get_pos(), 8)\n","\n","    pygame.transform.scale(draw_surf, (28, 28), model_surf)\n","    model_surfarray = pygame.surfarray.pixels3d(model_surf).astype(datatype)\n","    model_input = (model_surfarray[:, :, 0] - 128) / 128\n","    model_output = feedforward(model_input.T.flatten())[0]\n","\n","    screen.blit(draw_surf, (0, 0))\n","    width = 28\n","    for idx, prob in enumerate(model_output):\n","        c = int(prob * 200)\n","        draw_rect = pygame.Rect((idx * width, 0, width, width))\n","        pygame.draw.rect(screen, (c, c, c), draw_rect)\n","        draw_num_at_pos(screen, idx, draw_rect.center)\n","    screen.blit(model_surf, (0, width))\n","\n","    pygame.display.set_caption(f\"Guess: {model_output.argmax()}. TL: {model_input.max()}\")\n","\n","    pygame.display.flip()\n","    \n","pygame.quit()\n"]},{"cell_type":"code","execution_count":214,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9921875\n","-1.0\n","-1.0\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import random\n","\n","i = random.randint(0, 10000)\n","\n","print(test_vals[i].max())\n","print(test_vals[i].min())\n","\n","print(test_vals[i][0])\n","\n","\n","plt.imshow(test_vals[i].reshape((28, 28)))\n","plt.title(f\"E: {test_labels[i]}, O: {feedforward(test_vals[i])[0].argmax()}\")\n","plt.show()"]},{"cell_type":"code","execution_count":215,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0 0.0023\n","1 0.0245\n","2 0.053200000000000004\n","3 0.0241\n","4 0.0053\n","5 0.8075\n","6 0.0073\n","7 0.0678\n","8 0.0013000000000000002\n","9 0.006200000000000001\n"]}],"source":["from PIL import Image\n","\n","img = Image.open(\"MySevenDark.png\").convert('L')\n","\n","img_array = ((np.array(img, dtype=datatype) - 128) / 128)\n","img_flat = img_array.flatten()\n","\n","model_input = (img_flat - 128) / 128\n","model_output = feedforward(model_input.flatten())[0]\n","\n","plt.imshow(model_input.reshape((28, 28)))\n","plt.show()\n","\n","\n","for idx, i in enumerate(model_output):\n","    print(idx, (i // 0.0001) * 0.0001) "]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0.9999\n","1 0.0\n","2 0.0\n","3 0.0\n","4 0.0\n","5 0.0\n","6 0.0\n","7 0.0\n","8 0.0\n","9 0.0\n"]}],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":27352,"sourceId":34877,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
